# Deep Dive into Transformers, Neural Network & Backprop

Dive deep into Transformers, Neural Networks, and backpropagation. Explore cutting-edge AI, uncover insights, and empower your understanding of these transformative technologies.

<br/>

import Image from "next/image";

<div style={{ position: "relative" }}>
  <Image
    src="/static/img/memes/backpropAndTransformersMeme.png"
    alt="backprop & Transformers Meme"
    height="300"
    width="850"
    priority
  />
</div>

### Courses

- [Neural Network course](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) by 3Blue1Brown, Delve into the intricate world of neural networks through captivating animations and intuitive explanations. Gain a deep understanding of this fundamental ML concept in a visually engaging and enlightening way.

- [Neural Networks / Deep Learning](https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1) by StatQuest with Josh Starmer, includes everything you need to know about Neural Networks, from the basics, all the way to image classification with Convolutional Neural Networks.


### Articles

- [Introduction to Neural Networks â€” Part 1](https://medium.com/deep-learning-demystified/introduction-to-neural-networks-part-1-e13f132c6d7e) & [part 2](https://medium.com/deep-learning-demystified/introduction-to-neural-networks-part-2-c261a99f4138) by Harsha Bommana, explores the neural network's fundamental components, including neurons, their mathematical operations, and the significance of activation functions for addressing non-linear problems. It delves into various neural network types and offers examples of their applications in ML and deep learning.

- [How Transformers Work](https://towardsdatascience.com/transformers-141e32e69591): Discover the mechanics of Transformers, the revolutionary neural network technology harnessed by industry leaders like OpenAI and DeepMind. Gain valuable insights into the inner workings of these AI giants and explore their transformative applications in the world of ML.

- [The illustrated transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar provides an in-depth technical examination of the transformer framework, offering detailed insights into its structure and functionality.

- [Yes you should understand backprop](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b) by Andrej Karpathy, depth post on backpropagation provides valuable insights into the intricacies of this crucial technique.

- [RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html): Explore Chip Huyen's insights into RLHF, a transformative approach that enhances the predictability and human-friendliness of LLMs. Gain valuable knowledge about this crucial aspect of systems like ChatGPT, shedding light on its significance and potential impact.

- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/): This post provides an annotated paper implementation of ["Attention Is All You Need"](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf), presented in a line-by-line format. It reorganizes and omits certain sections from the original paper while incorporating comments, offering a fully functional implementation with available code in a concise format. Requires some knowledge of PyTorch.

### Explainers

- Explore the video article [Attention Is All You Need video](https://www.youtube.com/watch?v=XowwKOAWYoQ) a visual journey through the groundbreaking concepts introduced in the original paper. If the written article seems complex, this video provides an accessible and insightful way to grasp the key ideas behind the transformative Transformer architecture.

- [Introduction to Transformers](https://www.youtube.com/watch?v=XfpMkf4rD6E&t=2287s) by Andrej Karpathy. Since their groundbreaking introduction in 2017, transformers have transformed NLP and expanded into various domains of Deep Learning, including computer vision (CV), reinforcement learning (RL), Generative Adversarial Networks (GANs), Speech, and even Biology. They played a pivotal role in the development of powerful language models like GPT-3 and were instrumental in DeepMind's remarkable AlphaFold2 project, addressing protein folding challenges.

- [A friendly introduction to Deep Learning and Neural Networks](https://www.youtube.com/watch?v=BR9h47Jtqyw&list=PLs8w1Cdi-zvavXlPXEAsWIh4Cgh83pZPO&index=1&t=1s) by Serrano.Academy, introduces deep learning and neural networks, explaining AI, ML, and deep learning basics. It showcases real-world applications like image recognition and natural language processing.

- [Watching Neural Networks Learn](https://www.youtube.com/watch?v=TkwXa7Cvfr8&t=1191s) by Emergent Garden, demonstrates neural network learning, focusing on recognizing handwritten digits. Trained on a dataset, it showcases the network's improving accuracy, revealing its capacity for image recognition and evolving internal representations over time.

- [Why Neural Networks can learn (almost) anything](https://www.youtube.com/watch?v=0QczhVg5HaI) by Emergent Garden, provides a fascinating insight into the power of neural networks and their ability to learn complex patterns.

- [The backpropagation algorithm](https://www.youtube.com/watch?v=VCT1N0EsGj0) by Geoffrey Hinton delves into the fundamentals of backpropagation, a key algorithm in training neural networks. Hinton's teachings include insights on learning with the idea behind it, the role of hidden units, and learning through perturbing weights, discusses the concept of learning by using perturbations, providing valuable knowledge and techniques for training neural networks effectively.

- [Tensors for Neural Networks, Clearly Explained!!!](https://www.youtube.com/watch?v=L35fFDpwIM4) by StatQuest with Josh Starmer. Tensors are fundamental data structures in machine learning, representing multi-dimensional arrays that store and manipulate information, enabling the foundation for deep learning and neural network operations.


